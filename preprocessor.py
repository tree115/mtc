"""
X·ª≠ l√Ω extinction correction v√† cleaning c∆° b·∫£n
ƒê√£ s·ª≠a ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi c·∫£ 'flux' v√† 'Flux' column names
"""
import numpy as np
import pandas as pd
import extinction
from astropy.cosmology import Planck18 as cosmo
from astropy import units as u
from config import EFF_WAVELENGTHS, R_V
import warnings
warnings.filterwarnings('ignore')


class RobustPreprocessor:
    """X·ª≠ l√Ω extinction v√† t√≠nh to√°n v·∫≠t l√Ω c∆° b·∫£n - ROBUST VERSION"""
    
    def __init__(self):
        self.eff_wavelengths = EFF_WAVELENGTHS
        self.R_V = R_V
        
    def _get_column_name(self, df, possible_names):
        """T√¨m column name trong c√°c options"""
        for name in possible_names:
            if name in df.columns:
                return name
        raise KeyError(f"Kh√¥ng t√¨m th·∫•y column n√†o trong {possible_names}")
        
    def correct_extinction(self, df):
        """
        Hi·ªáu ch·ªânh extinction cho flux d√πng Fitzpatrick (1999)
        H·ªó tr·ª£ c·∫£ 'flux' v√† 'Flux' column names
        """
        df = df.copy()
        
        if 'flux_corrected' in df.columns:
            print("‚ö†Ô∏è  flux_corrected ƒë√£ t·ªìn t·∫°i, b·ªè qua")
            return df
        
        print("üåå ƒêang hi·ªáu ch·ªânh extinction...")
        
        # X√°c ƒë·ªãnh column names
        flux_col = self._get_column_name(df, ['flux', 'Flux', 'FLUX'])
        flux_err_col = self._get_column_name(df, ['flux_err', 'Flux_err', 'FLUX_ERR'])
        
        # Ki·ªÉm tra required columns
        required_cols = [flux_col, 'Filter', 'EBV']
        for col in required_cols:
            if col not in df.columns:
                raise KeyError(f"Thi·∫øu column b·∫Øt bu·ªôc: {col}")
        
        # T·∫°o c·ªôt m·ªõi
        flux_corrected_list = []
        
        for _, row in df.iterrows():
            try:
                # L·∫•y hi·ªáu ch·ªânh extinction
                A_v = self.R_V * row['EBV']
                wave = np.array([self.eff_wavelengths[row['Filter']]])
                A_lambda = extinction.fitzpatrick99(wave, A_v, self.R_V)[0]
                
                # Hi·ªáu ch·ªânh flux
                flux_corr = row[flux_col] * 10**(0.4 * A_lambda)
                flux_corrected_list.append(flux_corr)
            except Exception as e:
                # N·∫øu c√≥ l·ªói, d√πng flux g·ªëc
                print(f"‚ö†Ô∏è  L·ªói extinction correction: {e}, d√πng flux g·ªëc")
                flux_corrected_list.append(row[flux_col])
        
        df['flux_corrected'] = flux_corrected_list
        
        # X·ª≠ l√Ω flux qu√° nh·ªè/√¢m
        df['flux_positive'] = df['flux_corrected'].clip(lower=1e-9)
        
        print(f"‚úÖ ƒê√£ hi·ªáu ch·ªânh extinction cho {len(df)} observations")
        return df
    
    def calculate_absolute_magnitude(self, df):
        """
        T√≠nh ƒë·ªô s√°ng tuy·ªát ƒë·ªëi t·ª´ redshift
        """
        df = df.copy()
        
        if 'absolute_mag' in df.columns:
            print("‚ö†Ô∏è  absolute_mag ƒë√£ t·ªìn t·∫°i, b·ªè qua")
            return df
        
        print("üå† ƒêang t√≠nh ƒë·ªô s√°ng tuy·ªát ƒë·ªëi...")
        
        # Ki·ªÉm tra required columns
        required_cols = ['flux_positive', 'Z', 'object_id']
        for col in required_cols:
            if col not in df.columns:
                raise KeyError(f"Thi·∫øu column b·∫Øt bu·ªôc: {col}")
        
        # T√≠nh kho·∫£ng c√°ch t·ª´ redshift (x·ª≠ l√Ω redshift <= 0)
        df['Z_clean'] = df['Z'].copy()
        df.loc[df['Z_clean'] <= 0, 'Z_clean'] = 1e-6
        
        try:
            # T√≠nh luminosity distance (pc)
            dist_pc = cosmo.luminosity_distance(df['Z_clean'].values).to(u.pc).value
            df['distance_pc'] = dist_pc
            
            # T√≠nh ƒë·ªô s√°ng bi·ªÉu ki·∫øn
            df['apparent_mag'] = -2.5 * np.log10(df['flux_positive'])
            
            # T√≠nh ƒë·ªô s√°ng tuy·ªát ƒë·ªëi: M = m - 5*log10(d/10)
            df['absolute_mag'] = df['apparent_mag'] - 5 * (np.log10(df['distance_pc']) - 1)
            
            # T√≠nh SNR
            flux_err_col = self._get_column_name(df, ['flux_err', 'Flux_err', 'FLUX_ERR'])
            df['snr'] = df['flux_corrected'] / (df[flux_err_col] + 1e-9)
            
        except Exception as e:
            print(f"‚ö†Ô∏è  L·ªói t√≠nh absolute magnitude: {e}")
            # Set default values
            df['distance_pc'] = 1e6
            df['apparent_mag'] = 0
            df['absolute_mag'] = 0
            df['snr'] = 1
        
        # X√≥a c·ªôt t·∫°m
        if 'Z_clean' in df.columns:
            df = df.drop(columns=['Z_clean'])
        
        print(f"‚úÖ ƒê√£ t√≠nh absolute magnitude cho {len(df)} observations")
        return df
    
    def clean_data(self, df):
        """
        L√†m s·∫°ch d·ªØ li·ªáu c∆° b·∫£n
        """
        df = df.copy()
        
        print("üßπ ƒêang l√†m s·∫°ch d·ªØ li·ªáu...")
        
        # 1. S·∫Øp x·∫øp theo object_id v√† th·ªùi gian
        sort_cols = []
        if 'object_id' in df.columns:
            sort_cols.append('object_id')
        if 'mjd' in df.columns:
            sort_cols.append('mjd')
        
        if sort_cols:
            df = df.sort_values(sort_cols)
        
        # 2. Ki·ªÉm tra v√† x·ª≠ l√Ω missing values
        missing_cols = df.columns[df.isnull().any()].tolist()
        if missing_cols:
            print(f"‚ö†Ô∏è  C√≥ missing values trong: {missing_cols[:5]}...")  # Hi·ªÉn th·ªã 5 c·ªôt ƒë·∫ßu
            
            # Fill missing EBV v·ªõi 0 (kh√¥ng extinction)
            if 'EBV' in df.columns:
                df['EBV'] = df['EBV'].fillna(0)
            
            # Fill missing Filter (r·∫•t hi·∫øm)
            if 'Filter' in df.columns:
                df['Filter'] = df['Filter'].fillna('r')  # m·∫∑c ƒë·ªãnh filter r
            
            # Fill missing flux_err v·ªõi median
            flux_err_col = self._get_column_name(df, ['flux_err', 'Flux_err', 'FLUX_ERR'])
            if flux_err_col in df.columns:
                median_flux_err = df[flux_err_col].median()
                df[flux_err_col] = df[flux_err_col].fillna(median_flux_err)
        
        # 3. Lo·∫°i b·ªè flux_err = 0 (kh√¥ng h·ª£p l·ªá)
        flux_err_col = self._get_column_name(df, ['flux_err', 'Flux_err', 'FLUX_ERR'])
        if flux_err_col in df.columns:
            zero_err_mask = df[flux_err_col] == 0
            if zero_err_mask.any():
                print(f"‚ö†Ô∏è  Lo·∫°i b·ªè {zero_err_mask.sum()} observations c√≥ flux_err = 0")
                df = df[~zero_err_mask].copy()
        
        print(f"‚úÖ ƒê√£ l√†m s·∫°ch: {len(df)} observations")
        return df
    
    def add_basic_stats(self, df):
        """Th√™m th·ªëng k√™ c∆° b·∫£n cho m·ªói object"""
        df = df.copy()
        
        # Ki·ªÉm tra required columns
        if 'object_id' not in df.columns:
            print("‚ö†Ô∏è  Kh√¥ng c√≥ object_id, b·ªè qua basic stats")
            return df
        
        try:
            # T√≠nh to√°n theo object_id
            grouped = df.groupby('object_id')
            
            # S·ªë observations m·ªói object
            obs_counts = grouped.size()
            df['obs_count_total'] = df['object_id'].map(obs_counts)
            
            # S·ªë filter kh√°c nhau
            if 'Filter' in df.columns:
                filter_counts = grouped['Filter'].nunique()
                df['filter_count'] = df['object_id'].map(filter_counts)
            
            # Th·ªùi gian quan s√°t span
            if 'mjd' in df.columns:
                time_spans = grouped['mjd'].apply(lambda x: x.max() - x.min())
                df['mjd_span'] = df['object_id'].map(time_spans)
            
        except Exception as e:
            print(f"‚ö†Ô∏è  L·ªói t√≠nh basic stats: {e}")
        
        return df
    
    def preprocess_pipeline(self, df):
        """
        Pipeline x·ª≠ l√Ω ƒë·∫ßy ƒë·ªß - ROBUST VERSION
        """
        print("="*60)
        print("üöÄ B·∫ÆT ƒê·∫¶U PREPROCESSING PIPELINE")
        print("="*60)
        
        # L∆∞u s·ªë observations ban ƒë·∫ßu
        initial_count = len(df)
        initial_objects = df['object_id'].nunique() if 'object_id' in df.columns else 0
        
        try:
            # 1. Hi·ªáu ch·ªânh extinction
            df = self.correct_extinction(df)
            
            # 2. T√≠nh absolute magnitude
            df = self.calculate_absolute_magnitude(df)
            
            # 3. L√†m s·∫°ch d·ªØ li·ªáu
            df = self.clean_data(df)
            
            # 4. Th√™m th√¥ng tin th·ªëng k√™ c∆° b·∫£n
            df = self.add_basic_stats(df)
            
            print(f"\nüìä K·∫æT QU·∫¢ PREPROCESSING:")
            print(f"   S·ªë observations: {initial_count} ‚Üí {len(df)}")
            print(f"   S·ªë object_id duy nh·∫•t: {df['object_id'].nunique()}")
            
            # Hi·ªÉn th·ªã columns m·ªõi ƒë∆∞·ª£c t·∫°o
            original_cols = ['flux', 'Flux', 'flux_err', 'Flux_err', 'object_id', 'mjd', 
                           'Filter', 'EBV', 'Z', 'FLUX', 'FLUX_ERR']
            new_cols = [c for c in df.columns if c not in original_cols]
            print(f"   Columns m·ªõi ƒë∆∞·ª£c t·∫°o: {len(new_cols)} columns")
            if len(new_cols) <= 10:
                print(f"   New columns: {new_cols}")
            
            return df
            
        except Exception as e:
            print(f"‚ùå L·ªói trong preprocessing pipeline: {e}")
            print("‚ö†Ô∏è  Tr·∫£ v·ªÅ dataframe g·ªëc v·ªõi minimal processing")
            
            # Minimal preprocessing
            df = df.copy()
            if 'object_id' in df.columns and 'mjd' in df.columns:
                df = df.sort_values(['object_id', 'mjd'])
            
            return df


# Legacy class for backward compatibility
class Preprocessor(RobustPreprocessor):
    """Legacy class - extends RobustPreprocessor"""
    def __init__(self):
        super().__init__()
        print("‚ö†Ô∏è  Using legacy Preprocessor. Consider using RobustPreprocessor.")